{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9973ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0571c7f8",
   "metadata": {},
   "source": [
    "## Perceptrons\n",
    "![MLP](images/perceptron1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a91ed3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfe967e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0c31442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f470c8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.3, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.7, 0.4],\n",
       "       [1.4, 0.3],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.5, 0.1],\n",
       "       [1.5, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.4, 0.1],\n",
       "       [1.1, 0.1],\n",
       "       [1.2, 0.2],\n",
       "       [1.5, 0.4],\n",
       "       [1.3, 0.4],\n",
       "       [1.4, 0.3],\n",
       "       [1.7, 0.3],\n",
       "       [1.5, 0.3],\n",
       "       [1.7, 0.2],\n",
       "       [1.5, 0.4],\n",
       "       [1. , 0.2],\n",
       "       [1.7, 0.5],\n",
       "       [1.9, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.6, 0.4],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.5, 0.4],\n",
       "       [1.5, 0.1],\n",
       "       [1.4, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.2, 0.2],\n",
       "       [1.3, 0.2],\n",
       "       [1.4, 0.1],\n",
       "       [1.3, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.3, 0.3],\n",
       "       [1.3, 0.3],\n",
       "       [1.3, 0.2],\n",
       "       [1.6, 0.6],\n",
       "       [1.9, 0.4],\n",
       "       [1.4, 0.3],\n",
       "       [1.6, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [4.7, 1.4],\n",
       "       [4.5, 1.5],\n",
       "       [4.9, 1.5],\n",
       "       [4. , 1.3],\n",
       "       [4.6, 1.5],\n",
       "       [4.5, 1.3],\n",
       "       [4.7, 1.6],\n",
       "       [3.3, 1. ],\n",
       "       [4.6, 1.3],\n",
       "       [3.9, 1.4],\n",
       "       [3.5, 1. ],\n",
       "       [4.2, 1.5],\n",
       "       [4. , 1. ],\n",
       "       [4.7, 1.4],\n",
       "       [3.6, 1.3],\n",
       "       [4.4, 1.4],\n",
       "       [4.5, 1.5],\n",
       "       [4.1, 1. ],\n",
       "       [4.5, 1.5],\n",
       "       [3.9, 1.1],\n",
       "       [4.8, 1.8],\n",
       "       [4. , 1.3],\n",
       "       [4.9, 1.5],\n",
       "       [4.7, 1.2],\n",
       "       [4.3, 1.3],\n",
       "       [4.4, 1.4],\n",
       "       [4.8, 1.4],\n",
       "       [5. , 1.7],\n",
       "       [4.5, 1.5],\n",
       "       [3.5, 1. ],\n",
       "       [3.8, 1.1],\n",
       "       [3.7, 1. ],\n",
       "       [3.9, 1.2],\n",
       "       [5.1, 1.6],\n",
       "       [4.5, 1.5],\n",
       "       [4.5, 1.6],\n",
       "       [4.7, 1.5],\n",
       "       [4.4, 1.3],\n",
       "       [4.1, 1.3],\n",
       "       [4. , 1.3],\n",
       "       [4.4, 1.2],\n",
       "       [4.6, 1.4],\n",
       "       [4. , 1.2],\n",
       "       [3.3, 1. ],\n",
       "       [4.2, 1.3],\n",
       "       [4.2, 1.2],\n",
       "       [4.2, 1.3],\n",
       "       [4.3, 1.3],\n",
       "       [3. , 1.1],\n",
       "       [4.1, 1.3],\n",
       "       [6. , 2.5],\n",
       "       [5.1, 1.9],\n",
       "       [5.9, 2.1],\n",
       "       [5.6, 1.8],\n",
       "       [5.8, 2.2],\n",
       "       [6.6, 2.1],\n",
       "       [4.5, 1.7],\n",
       "       [6.3, 1.8],\n",
       "       [5.8, 1.8],\n",
       "       [6.1, 2.5],\n",
       "       [5.1, 2. ],\n",
       "       [5.3, 1.9],\n",
       "       [5.5, 2.1],\n",
       "       [5. , 2. ],\n",
       "       [5.1, 2.4],\n",
       "       [5.3, 2.3],\n",
       "       [5.5, 1.8],\n",
       "       [6.7, 2.2],\n",
       "       [6.9, 2.3],\n",
       "       [5. , 1.5],\n",
       "       [5.7, 2.3],\n",
       "       [4.9, 2. ],\n",
       "       [6.7, 2. ],\n",
       "       [4.9, 1.8],\n",
       "       [5.7, 2.1],\n",
       "       [6. , 1.8],\n",
       "       [4.8, 1.8],\n",
       "       [4.9, 1.8],\n",
       "       [5.6, 2.1],\n",
       "       [5.8, 1.6],\n",
       "       [6.1, 1.9],\n",
       "       [6.4, 2. ],\n",
       "       [5.6, 2.2],\n",
       "       [5.1, 1.5],\n",
       "       [5.6, 1.4],\n",
       "       [6.1, 2.3],\n",
       "       [5.6, 2.4],\n",
       "       [5.5, 1.8],\n",
       "       [4.8, 1.8],\n",
       "       [5.4, 2.1],\n",
       "       [5.6, 2.4],\n",
       "       [5.1, 2.3],\n",
       "       [5.1, 1.9],\n",
       "       [5.9, 2.3],\n",
       "       [5.7, 2.5],\n",
       "       [5.2, 2.3],\n",
       "       [5. , 1.9],\n",
       "       [5.2, 2. ],\n",
       "       [5.4, 2.3],\n",
       "       [5.1, 1.8]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data[:, (2, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a640136",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-aca175b4ea52>:2: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = (iris.target == 0).astype(np.int)  # Iris setosa?\n"
     ]
    }
   ],
   "source": [
    "X = iris.data[:, (2, 3)]  # petal length, petal width\n",
    "y = (iris.target == 0).astype(np.int)  # Iris setosa?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69c02dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbc1923c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_clf = Perceptron()\n",
    "per_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6426fc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = per_clf.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69e8243c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed8496c",
   "metadata": {},
   "source": [
    "## The Multilayer Perceptron and Backpropagation\n",
    "An MLP is composed of one (passthrough) input layer, one or more layers of TLUs, called hidden layers, and one final layer of TLUs called the output layer (see Figure 10-7). The layers close to the input layer are usually called the lower layers, and the ones close to the outputs are usually called the upper layers. Every layer except the output layer includes a bias neuron and is fully connected to the next layer.\n",
    "\n",
    "![MLP](images/mlp1.png)\n",
    "\n",
    "Algorithm:\n",
    "Let’s run through this algorithm in a bit more detail:\n",
    "\n",
    "-It handles one mini-batch at a time (for example, containing 32 instances each), and it goes through the full training set multiple times. Each pass is called an epoch.\n",
    "\n",
    "-Each mini-batch is passed to the network’s input layer, which sends it to the first hidden layer. The algorithm then computes the output of all the neurons in this layer (for every instance in the mini-batch). The result is passed on to the next layer, its output is computed and passed to the next layer, and so on until we get the output of the last layer, the output layer. This is the forward pass: it is exactly like making predictions, except all intermediate results are preserved since they are needed for the backward pass.\n",
    "\n",
    "-Next, the algorithm measures the network’s output error (i.e., it uses a loss function that compares the desired output and the actual output of the network, and returns some measure of the error).\n",
    "\n",
    "-Then it computes how much each output connection contributed to the error. This is done analytically by applying the chain rule (perhaps the most fundamental rule in calculus), which makes this step fast and precise.\n",
    "\n",
    "-The algorithm then measures how much of these error contributions came from each connection in the layer below, again using the chain rule, working backward until the algorithm reaches the input layer. As explained earlier, this reverse pass efficiently measures the error gradient across all the connection weights in the network by propagating the error gradient backward through the network (hence the name of the algorithm).\n",
    "\n",
    "-Finally, the algorithm performs a Gradient Descent step to tweak all the connection weights in the network, using the error gradients it just computed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15fbaf9",
   "metadata": {},
   "source": [
    "## Implementing MLPs with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b4b9dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65c766e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77aa7b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f945cc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed9dd203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e92851ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7bd5767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create validation set\n",
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "718a6f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 7, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b7f8ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "537f0038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign class names to the labels\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "015e26fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22046a84",
   "metadata": {},
   "source": [
    " Steps:\n",
    " - The first line creates a Sequential model. This is the simplest kind of Keras model for neural networks that are just composed of a single stack of layers connected sequentially. This is called the Sequential API.\n",
    " \n",
    "\n",
    " - Next, we build the first layer and add it to the model. It is a Flatten layer whose role is to convert each input image into a 1D array: if it receives input data X, it computes X.reshape(-1, 28*28). This layer does not have any parameters; it is just there to do some simple preprocessing. Since it is the first layer in the model, you should specify the input_shape, which doesn’t include the batch size, only the shape of the instances. Alternatively, you could add a keras.layers.InputLayer as the first layer, setting input_shape=[28,28].\n",
    " \n",
    "\n",
    " - Next we add a Dense hidden layer with 300 neurons. It will use the ReLU activation function. Each Dense layer manages its own weight matrix, containing all the connection weights between the neurons and their inputs. It also manages a vector of bias terms (one per neuron). When it receives some input data, it computes Equation 10-2.\n",
    " \n",
    "\n",
    " - Then we add a second Dense hidden layer with 100 neurons, also using the ReLU activation function.\n",
    " \n",
    "\n",
    " - Finally, we add a Dense output layer with 10 neurons (one per class), using the softmax activation function (because the classes are exclusive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a24f1f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model using Sequential API\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1980ae9e",
   "metadata": {},
   "source": [
    "the first hidden layer has 784 × 300 connection weights, plus 300 bias terms, which adds up to 235,500 parameters! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3b380a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model sumary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e2d83b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x1a03893a0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1a03a54f0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1a0278490>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1a03a58e0>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetch a layer by its index\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c89b7cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61c3d985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cefe8f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense') is hidden1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02ed007",
   "metadata": {},
   "source": [
    "All the parameters of a layer can be accessed using its get_weights() and set_weights() methods. For a Dense layer, this includes both the connection weights and the bias terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4fbeadc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad47f362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03074662,  0.07257129, -0.02808697, ..., -0.04457491,\n",
       "         0.00847841,  0.00602874],\n",
       "       [ 0.00452739,  0.00675081,  0.04277879, ..., -0.03408002,\n",
       "        -0.06502568, -0.03593531],\n",
       "       [ 0.04956739,  0.03863426, -0.0281074 , ..., -0.02228071,\n",
       "        -0.00026775, -0.00055734],\n",
       "       ...,\n",
       "       [-0.0266091 , -0.02139368, -0.03776157, ..., -0.06708038,\n",
       "        -0.06357871, -0.01378268],\n",
       "       [-0.06263878,  0.04254121,  0.04766677, ..., -0.00157083,\n",
       "        -0.05907144,  0.03040587],\n",
       "       [-0.04768714, -0.05154674,  0.01604967, ..., -0.05716387,\n",
       "         0.00172167, -0.0690331 ]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "486f4186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "178bc1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae307ac7",
   "metadata": {},
   "source": [
    "### compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1920b2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fc68fa",
   "metadata": {},
   "source": [
    "This code requires some explanation. First, we use the \"sparse_categorical_crossentropy\" loss because we have sparse labels (i.e., for each instance, there is just a target class index, from 0 to 9 in this case), and the classes are exclusive. If instead we had one target probability per class for each instance (such as one-hot vectors, e.g. [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.] to represent class 3), then we would need to use the \"categorical_crossentropy\" loss instead. If we were doing binary classification or multilabel binary classification, then we would use the \"sigmoid\" (i.e., logistic) activation function in the output layer instead of the \"softmax\" activation function, and we would use the \"binary_crossentropy\" loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d576596",
   "metadata": {},
   "source": [
    "### TRAINING AND EVALUATING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05a83d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 1.0621 - accuracy: 0.6567 - val_loss: 0.5360 - val_accuracy: 0.8216\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 2s 926us/step - loss: 0.5069 - accuracy: 0.8245 - val_loss: 0.4467 - val_accuracy: 0.8494\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 2s 905us/step - loss: 0.4576 - accuracy: 0.8408 - val_loss: 0.4210 - val_accuracy: 0.8578\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 2s 947us/step - loss: 0.4258 - accuracy: 0.8513 - val_loss: 0.4144 - val_accuracy: 0.8580\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 2s 981us/step - loss: 0.4033 - accuracy: 0.8609 - val_loss: 0.3905 - val_accuracy: 0.8646\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 2s 900us/step - loss: 0.3802 - accuracy: 0.8670 - val_loss: 0.3814 - val_accuracy: 0.8708\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 2s 903us/step - loss: 0.3747 - accuracy: 0.8666 - val_loss: 0.3725 - val_accuracy: 0.8704\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 2s 887us/step - loss: 0.3539 - accuracy: 0.8744 - val_loss: 0.3817 - val_accuracy: 0.8658\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 2s 901us/step - loss: 0.3475 - accuracy: 0.8798 - val_loss: 0.3798 - val_accuracy: 0.8616\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 2s 890us/step - loss: 0.3391 - accuracy: 0.8794 - val_loss: 0.3518 - val_accuracy: 0.8734\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 2s 898us/step - loss: 0.3268 - accuracy: 0.8828 - val_loss: 0.3581 - val_accuracy: 0.8712\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 2s 912us/step - loss: 0.3208 - accuracy: 0.8857 - val_loss: 0.3330 - val_accuracy: 0.8822\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3168 - accuracy: 0.8890 - val_loss: 0.3248 - val_accuracy: 0.8852\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 2s 970us/step - loss: 0.3027 - accuracy: 0.8921 - val_loss: 0.3246 - val_accuracy: 0.8882\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 2s 915us/step - loss: 0.2921 - accuracy: 0.8948 - val_loss: 0.3275 - val_accuracy: 0.8834\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 2s 948us/step - loss: 0.2929 - accuracy: 0.8950 - val_loss: 0.3214 - val_accuracy: 0.8866\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 2s 913us/step - loss: 0.2811 - accuracy: 0.9019 - val_loss: 0.3337 - val_accuracy: 0.8798\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 2s 944us/step - loss: 0.2751 - accuracy: 0.9015 - val_loss: 0.3166 - val_accuracy: 0.8860\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 2s 935us/step - loss: 0.2767 - accuracy: 0.9006 - val_loss: 0.3030 - val_accuracy: 0.8962\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 2s 917us/step - loss: 0.2690 - accuracy: 0.9029 - val_loss: 0.3354 - val_accuracy: 0.8804\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 2s 875us/step - loss: 0.2637 - accuracy: 0.9062 - val_loss: 0.3186 - val_accuracy: 0.8872\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 2s 900us/step - loss: 0.2596 - accuracy: 0.9067 - val_loss: 0.3127 - val_accuracy: 0.8886\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 2s 934us/step - loss: 0.2524 - accuracy: 0.9104 - val_loss: 0.2970 - val_accuracy: 0.8936\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 2s 954us/step - loss: 0.2504 - accuracy: 0.9108 - val_loss: 0.3249 - val_accuracy: 0.8856\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 2s 958us/step - loss: 0.2435 - accuracy: 0.9132 - val_loss: 0.3159 - val_accuracy: 0.8840\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 2s 924us/step - loss: 0.2401 - accuracy: 0.9125 - val_loss: 0.3073 - val_accuracy: 0.8898\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 2s 923us/step - loss: 0.2368 - accuracy: 0.9148 - val_loss: 0.2996 - val_accuracy: 0.8948\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 2s 909us/step - loss: 0.2341 - accuracy: 0.9149 - val_loss: 0.2932 - val_accuracy: 0.9006\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 2s 893us/step - loss: 0.2252 - accuracy: 0.9193 - val_loss: 0.2951 - val_accuracy: 0.8968\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 2s 874us/step - loss: 0.2283 - accuracy: 0.9161 - val_loss: 0.2940 - val_accuracy: 0.8978\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, \n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42827ea",
   "metadata": {},
   "source": [
    "We pass it the input features (X_train) and the target classes (y_train), as well as the number of epochs to train (or else it would default to just 1, which would definitely not be enough to converge to a good solution). We also pass a validation set (this is optional). Keras will measure the loss and the extra metrics on this set at the end of each epoch, which is very useful to see how well the model really performs. If the performance on the training set is much better than on the validation set, your model is probably overfitting the training set (or there is a bug, such as a data mismatch between the training set and the validation set).\n",
    "\n",
    "Note: Instead of passing a validation set using the validation_data argument, you could set validation_split to the ratio of the training set that you want Keras to use for validation. For example, validation_split=0.1 tells Keras to use the last 10% of the data (before shuffling) for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f602ab69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.7532063722610474,\n",
       "  0.4956967234611511,\n",
       "  0.4485000669956207,\n",
       "  0.4197353422641754,\n",
       "  0.3986221253871918,\n",
       "  0.38283711671829224,\n",
       "  0.36938220262527466,\n",
       "  0.3563830852508545,\n",
       "  0.345756858587265,\n",
       "  0.33756962418556213,\n",
       "  0.32794705033302307,\n",
       "  0.32037585973739624,\n",
       "  0.3129996061325073,\n",
       "  0.3054552674293518,\n",
       "  0.2990412414073944,\n",
       "  0.29299619793891907,\n",
       "  0.2860717475414276,\n",
       "  0.28072765469551086,\n",
       "  0.2762213945388794,\n",
       "  0.27157384157180786,\n",
       "  0.26518747210502625,\n",
       "  0.2607956528663635,\n",
       "  0.25601112842559814,\n",
       "  0.2512616515159607,\n",
       "  0.24730336666107178,\n",
       "  0.24367444217205048,\n",
       "  0.23847439885139465,\n",
       "  0.23498769104480743,\n",
       "  0.23005838692188263,\n",
       "  0.2274387627840042],\n",
       " 'accuracy': [0.751836359500885,\n",
       "  0.8271818161010742,\n",
       "  0.8432000279426575,\n",
       "  0.8532363772392273,\n",
       "  0.8614909052848816,\n",
       "  0.8651454448699951,\n",
       "  0.869381844997406,\n",
       "  0.8743090629577637,\n",
       "  0.8789636492729187,\n",
       "  0.8799272775650024,\n",
       "  0.8827090859413147,\n",
       "  0.8858181834220886,\n",
       "  0.8896181583404541,\n",
       "  0.8912727236747742,\n",
       "  0.8927817940711975,\n",
       "  0.8953090906143188,\n",
       "  0.8985818028450012,\n",
       "  0.89936363697052,\n",
       "  0.9002545475959778,\n",
       "  0.902400016784668,\n",
       "  0.9048363566398621,\n",
       "  0.9062545299530029,\n",
       "  0.9078909158706665,\n",
       "  0.9103817939758301,\n",
       "  0.9113818407058716,\n",
       "  0.9122545719146729,\n",
       "  0.9143272638320923,\n",
       "  0.9154545664787292,\n",
       "  0.9173272848129272,\n",
       "  0.9175454378128052],\n",
       " 'val_loss': [0.5359503626823425,\n",
       "  0.4466842710971832,\n",
       "  0.4210300147533417,\n",
       "  0.41435331106185913,\n",
       "  0.39049461483955383,\n",
       "  0.3813861906528473,\n",
       "  0.37248528003692627,\n",
       "  0.3817434012889862,\n",
       "  0.3798476457595825,\n",
       "  0.35180845856666565,\n",
       "  0.3581078052520752,\n",
       "  0.33301427960395813,\n",
       "  0.3247833847999573,\n",
       "  0.3245915174484253,\n",
       "  0.3275422155857086,\n",
       "  0.3213716149330139,\n",
       "  0.33370357751846313,\n",
       "  0.3165818750858307,\n",
       "  0.30301883816719055,\n",
       "  0.3353774845600128,\n",
       "  0.3186430037021637,\n",
       "  0.312719464302063,\n",
       "  0.2969519793987274,\n",
       "  0.32494866847991943,\n",
       "  0.315912663936615,\n",
       "  0.30729222297668457,\n",
       "  0.29957789182662964,\n",
       "  0.29315611720085144,\n",
       "  0.29513242840766907,\n",
       "  0.29400181770324707],\n",
       " 'val_accuracy': [0.8216000199317932,\n",
       "  0.849399983882904,\n",
       "  0.8578000068664551,\n",
       "  0.8579999804496765,\n",
       "  0.8646000027656555,\n",
       "  0.8708000183105469,\n",
       "  0.8704000115394592,\n",
       "  0.8658000230789185,\n",
       "  0.8615999817848206,\n",
       "  0.8733999729156494,\n",
       "  0.8712000250816345,\n",
       "  0.8822000026702881,\n",
       "  0.885200023651123,\n",
       "  0.8881999850273132,\n",
       "  0.883400022983551,\n",
       "  0.8866000175476074,\n",
       "  0.879800021648407,\n",
       "  0.8859999775886536,\n",
       "  0.8962000012397766,\n",
       "  0.8804000020027161,\n",
       "  0.8871999979019165,\n",
       "  0.8885999917984009,\n",
       "  0.8935999870300293,\n",
       "  0.8855999708175659,\n",
       "  0.8840000033378601,\n",
       "  0.8898000121116638,\n",
       "  0.8948000073432922,\n",
       "  0.900600016117096,\n",
       "  0.8967999815940857,\n",
       "  0.8978000283241272]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f1ccc7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b377c8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# learning plots\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3468fbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 649us/step - loss: 0.3228 - accuracy: 0.8850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.322834312915802, 0.8849999904632568]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d8a70a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsenv] *",
   "language": "python",
   "name": "conda-env-dsenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
